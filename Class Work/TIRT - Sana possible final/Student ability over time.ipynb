{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Modelling student ability over time using Temporal Item Response Theory\n",
    "\n",
    "We start by evaluating model performance / making sure it works right by fitting the model to a synthetic dataset where the true skill of each student is known. We use the synthetic dataset to compare standard IRT to TIRT.\n",
    "\n",
    "Once this is done, we fit a TIRT model to a real dataset to perform inference over student ability over time.\n",
    "\n",
    "Please remember to do all of the following as part of your project:\n",
    "\n",
    "● Build a statistical model of your scenario.\n",
    "\n",
    "● Compute posteriors over parameters of interest.\n",
    "\n",
    "● Make predictions about unobserved data.\n",
    "\n",
    "● Summarize, interpret, and report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volatility of student skill / day.\n",
    "gamma = 0.1\n",
    "\n",
    "n_students = 50\n",
    "n_exercises = 5\n",
    "n_days = 100\n",
    "exercise_difficulties = [np.random.randn() for _ in range(n_exercises)]\n",
    "\n",
    "data = []\n",
    "for student in range(n_students):\n",
    "    skill = np.random.randn()\n",
    "    for t in range(n_days):\n",
    "        exercise = np.random.randint(0, n_exercises)\n",
    "        difficulty = exercise_difficulties[exercise]\n",
    "        p = sigmoid(skill - difficulty)\n",
    "        outcome = int(np.random.rand() < p)\n",
    "        data.append(\n",
    "            {\n",
    "                'student': student+1,\n",
    "                'day': t+1,\n",
    "                'skill': skill,\n",
    "                'difficulty': difficulty,\n",
    "                'exercise': exercise+1,\n",
    "                'outcome': outcome,\n",
    "                'day_delta': 1\n",
    "            }\n",
    "        )\n",
    "        skill += gamma*np.random.randn()\n",
    "        \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>day</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>exercise</th>\n",
       "      <th>outcome</th>\n",
       "      <th>day_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411419</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.436412</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.461164</td>\n",
       "      <td>1.864996</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.485281</td>\n",
       "      <td>-1.798502</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.549098</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.665491</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.613614</td>\n",
       "      <td>-1.798502</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.529275</td>\n",
       "      <td>-1.189067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.659190</td>\n",
       "      <td>-1.798502</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.692068</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.840975</td>\n",
       "      <td>-1.189067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.745451</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.706191</td>\n",
       "      <td>-1.189067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.694309</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.593317</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1.622469</td>\n",
       "      <td>-0.540292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1.716107</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.806024</td>\n",
       "      <td>-1.798502</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.729800</td>\n",
       "      <td>-1.798502</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.568879</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.980466</td>\n",
       "      <td>1.864996</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.993299</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.055031</td>\n",
       "      <td>1.864996</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.014135</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.114871</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student  day     skill  difficulty  exercise  outcome  day_delta\n",
       "0         1    1  1.411419    1.019073         4        1          1\n",
       "1         1    2  1.436412   -0.540292         1        0          1\n",
       "2         1    3  1.461164    1.864996         3        0          1\n",
       "3         1    4  1.485281   -1.798502         2        0          1\n",
       "4         1    5  1.549098   -0.540292         1        0          1\n",
       "5         1    6  1.665491   -0.540292         1        0          1\n",
       "6         1    7  1.613614   -1.798502         2        0          1\n",
       "7         1    8  1.529275   -1.189067         0        1          1\n",
       "8         1    9  1.659190   -1.798502         2        0          1\n",
       "9         1   10  1.692068   -0.540292         1        0          1\n",
       "10        1   11  1.840975   -1.189067         0        0          1\n",
       "11        1   12  1.745451    1.019073         4        0          1\n",
       "12        1   13  1.706191   -1.189067         0        0          1\n",
       "13        1   14  1.694309   -0.540292         1        0          1\n",
       "14        1   15  1.593317   -0.540292         1        0          1\n",
       "15        1   16  1.622469   -0.540292         1        0          1\n",
       "16        1   17  1.716107    1.019073         4        1          1\n",
       "17        1   18  1.806024   -1.798502         2        0          1\n",
       "18        1   19  1.729800   -1.798502         2        0          1\n",
       "19        1   20  1.568879    1.019073         4        0          1\n",
       "20        2    1 -0.980466    1.864996         3        1          1\n",
       "21        2    2 -0.993299    1.019073         4        1          1\n",
       "22        2    3 -1.055031    1.864996         3        1          1\n",
       "23        2    4 -1.014135    1.019073         4        1          1\n",
       "24        2    5 -1.114871    1.019073         4        1          1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = [s for _, s in df.groupby('student')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = \"\"\"\n",
    "data {\n",
    "  int<lower=1> J;              // number of students\n",
    "  int<lower=1> K;              // number of questions\n",
    "  int<lower=1> N;              // number of observations\n",
    "  int<lower=1,upper=J> jj[N];  // student for observation n\n",
    "  int<lower=1,upper=K> kk[N];  // question for observation n\n",
    "  int<lower=0,upper=1> y[N];   // correctness for observation n\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real alpha[J];      // ability of student j - mean ability\n",
    "  real beta[K];       // difficulty of question k\n",
    "}\n",
    "\n",
    "model {\n",
    "  alpha ~ normal(0, 2);         // conservative broad prior\n",
    "  beta ~ normal(0, 2);          // conservative broad prior\n",
    "  for (n in 1:N) {\n",
    "    y[n] ~ bernoulli_logit(alpha[jj[n]] - beta[kk[n]]);\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_6abe31a017d04a046b0a01c96a875354 NOW.\n"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "stan_model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"J\": n_students,        # number of students\n",
    "  \"K\": n_exercises,       # number of questions\n",
    "  \"N\": df.shape[0],       # number of observations\n",
    "  \"jj\": df[\"student\"],    # student for observations\n",
    "  \"kk\": df[\"exercise\"],   # question for observations\n",
    "  \"y\": df[\"outcome\"]      # correctness for observations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample posterior distribution over lambda\n",
    "stan_results = stan_model.sampling(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_6abe31a017d04a046b0a01c96a875354.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "            mean se_mean     sd   2.5%    50%  97.5%  n_eff   Rhat\n",
      "alpha[1]    2.05    0.03   0.44   1.19   2.04   2.98    300   1.01\n",
      "alpha[2]    0.09    0.03   0.34  -0.54   0.09   0.75    145   1.01\n",
      "alpha[3]   -0.49    0.03   0.34  -1.12  -0.49   0.19    153   1.01\n",
      "alpha[4]   -0.21    0.03   0.34  -0.86  -0.21   0.44    141   1.01\n",
      "alpha[5]    1.57    0.03    0.4   0.81   1.58   2.38    204   1.01\n",
      "alpha[6]   -0.48    0.03   0.33  -1.13  -0.48    0.2    148   1.01\n",
      "alpha[7]   -0.42    0.03   0.34  -1.07  -0.42   0.23    144   1.01\n",
      "alpha[8]   -0.91    0.03   0.34  -1.57  -0.91  -0.25    149   1.01\n",
      "alpha[9]    -1.9    0.03   0.37  -2.64  -1.89  -1.19    174   1.01\n",
      "alpha[10]   0.95    0.03   0.36   0.27   0.94   1.66    168   1.01\n",
      "alpha[11]   0.32    0.03   0.34  -0.34   0.32   0.98    152   1.01\n",
      "alpha[12]  -0.88    0.03   0.34  -1.54  -0.88  -0.22    148   1.01\n",
      "alpha[13]  -0.33    0.03   0.33  -1.01  -0.32   0.33    148   1.01\n",
      "alpha[14]   1.86    0.03   0.42   1.06   1.86   2.71    233   1.01\n",
      "alpha[15]  -0.91    0.03   0.34  -1.56  -0.91  -0.24    151   1.01\n",
      "alpha[16]   0.16    0.03   0.34  -0.52   0.15    0.8    139   1.02\n",
      "alpha[17]  -0.28    0.03   0.34  -0.96  -0.28   0.38    143   1.01\n",
      "alpha[18]   0.31    0.03   0.34  -0.34    0.3    1.0    148   1.01\n",
      "alpha[19]  -1.96    0.03   0.38  -2.72  -1.96  -1.23    182   1.01\n",
      "alpha[20]   1.99    0.03   0.43   1.15   1.98   2.89    241   1.01\n",
      "alpha[21]   0.09    0.03   0.34  -0.55   0.09   0.73    144   1.01\n",
      "alpha[22]  -2.51    0.03   0.42  -3.38   -2.5  -1.72    230   1.01\n",
      "alpha[23]   0.05    0.03   0.34   -0.6   0.05   0.72    148   1.01\n",
      "alpha[24]  -1.17    0.03   0.35  -1.82  -1.17  -0.49    147   1.01\n",
      "alpha[25]  -2.12    0.03   0.39  -2.88  -2.13  -1.36    190   1.01\n",
      "alpha[26]   0.78    0.03   0.36   0.09   0.79   1.49    161   1.01\n",
      "alpha[27]   -0.2    0.03   0.33  -0.85   -0.2   0.46    143   1.01\n",
      "alpha[28]   0.33    0.03   0.35  -0.34   0.32   1.02    160   1.01\n",
      "alpha[29]  -0.08    0.03   0.34  -0.76  -0.07   0.61    154   1.01\n",
      "alpha[30]  -0.34    0.03   0.33  -1.01  -0.35   0.32    139   1.01\n",
      "alpha[31]  -0.49    0.03   0.34  -1.14  -0.49   0.17    141   1.01\n",
      "alpha[32]   1.53    0.03   0.39   0.79   1.52   2.34    194   1.01\n",
      "alpha[33]   -0.9    0.03   0.34  -1.56  -0.91  -0.22    150   1.01\n",
      "alpha[34]-5.6e-3    0.03   0.33  -0.66  -0.01   0.67    147   1.01\n",
      "alpha[35]   2.14    0.03   0.45   1.25   2.13   3.05    250   1.01\n",
      "alpha[36]   1.31    0.03   0.38    0.6   1.31   2.07    182   1.01\n",
      "alpha[37]   1.14    0.03   0.37   0.45   1.13   1.86    181   1.01\n",
      "alpha[38]   0.38    0.03   0.34  -0.29   0.38   1.07    145   1.01\n",
      "alpha[39]   0.82    0.03   0.36   0.14   0.82   1.52    165   1.01\n",
      "alpha[40]   2.34    0.03   0.48    1.4   2.33   3.31    336    1.0\n",
      "alpha[41]  -0.24    0.03   0.34  -0.91  -0.23   0.42    147   1.01\n",
      "alpha[42]   0.05    0.03   0.34  -0.62   0.05    0.7    146   1.01\n",
      "alpha[43]  -0.16    0.03   0.33   -0.8  -0.16   0.52    144   1.01\n",
      "alpha[44]   1.39    0.03   0.39   0.64   1.39   2.17    184   1.01\n",
      "alpha[45] 3.1e-3    0.03   0.34  -0.64 2.6e-3   0.63    143   1.01\n",
      "alpha[46]  -1.15    0.03   0.34  -1.82  -1.15  -0.48    153   1.01\n",
      "alpha[47]  -1.69    0.03   0.36   -2.4  -1.69  -1.01    159   1.01\n",
      "alpha[48]   0.88    0.03   0.36    0.2   0.88   1.59    167   1.01\n",
      "alpha[49]  -0.48    0.03   0.34  -1.13  -0.48    0.2    145   1.01\n",
      "alpha[50]  -0.08    0.03   0.34  -0.72  -0.08   0.58    140   1.01\n",
      "beta[1]    -0.81    0.03   0.28  -1.34  -0.82  -0.27    102   1.02\n",
      "beta[2]     0.05    0.03   0.28  -0.49   0.05   0.59    100   1.02\n",
      "beta[3]    -0.15    0.03   0.28  -0.69  -0.15    0.4     99   1.02\n",
      "beta[4]    -0.04    0.03   0.28  -0.56  -0.04    0.5    100   1.02\n",
      "beta[5]    -0.97    0.03   0.28  -1.51  -0.98  -0.43    101   1.02\n",
      "\n",
      "Samples were drawn using NUTS at Thu Dec  5 19:02:26 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(stan_results.stansummary(pars=['alpha', \"beta\"], probs=[0.025, 0.5, 0.975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = stan_results.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 1.0828417728395425\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "true_mean_skill = [df[\"skill\"].loc[df[\"student\"]==i].mean() for i in df[\"student\"].unique()]\n",
    "pred_mean_skill = [np.mean(samples[\"alpha\"][:,i]) for i in range(samples[\"alpha\"].shape[1])]\n",
    "\n",
    "mean_absolute_error = mean_absolute_error(mean_skill, pred_mean_skill)\n",
    "print(\"mean_absolute_error:\", mean_absolute_error)\n",
    "\n",
    "plt.hist(true_mean_skill, alpha=0.5, label=\"True skill\", bins=20)\n",
    "plt.hist(pred_mean_skill, alpha=0.5, label=\"Predicted skill\",  bins=20)\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.66572114,  0.10284477, -0.92870477, ...,  0.86206086,\n",
      "        -0.6385774 , -0.55189493],\n",
      "       [ 1.9957695 ,  0.24256375, -0.78504752, ...,  0.79841058,\n",
      "        -0.51916208, -0.29368307],\n",
      "       [ 1.93478147, -0.15823379, -0.83432246, ...,  0.96628654,\n",
      "        -0.36000963, -0.24719233],\n",
      "       ...,\n",
      "       [ 1.66913069, -0.45723592, -0.84026805, ...,  0.68374215,\n",
      "        -0.69764065, -0.55732406],\n",
      "       [ 1.59957459,  0.24418534, -0.88774654, ...,  0.93458137,\n",
      "        -0.60543155, -0.37082799],\n",
      "       [ 2.38849672,  0.35590439, -0.22776263, ...,  1.17909402,\n",
      "        -0.21850911, -0.1753027 ]])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(samples[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = \"\"\"\n",
    "data {\n",
    "  int<lower=1> J;              // number of students\n",
    "  int<lower=1> K;              // number of questions\n",
    "  int<lower=1> N;              // number of observations\n",
    "  int<lower=1,upper=J> jj[N];  // student for observation n\n",
    "  int<lower=1,upper=K> kk[N];  // question for observation n\n",
    "  int<lower=0,upper=1> y[N];   // correctness for observation n\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real alpha[J];      // ability of student j - mean ability\n",
    "  real beta[K];       // difficulty of question k\n",
    "}\n",
    "\n",
    "model {\n",
    "  alpha ~ std_normal();         // conservative broad prior\n",
    "  beta ~ std_normal();          // conservative broad prior\n",
    "  for (n in 1:N) {\n",
    "    y[n] ~ bernoulli_logit(alpha[jj[n]] - beta[kk[n]]);\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "stan_model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"J\": n_students,        # number of students\n",
    "  \"K\": n_exercises,       # number of questions\n",
    "  \"N\": df.shape[0],       # number of observations\n",
    "  \"jj\": df[\"student\"],    # student for observations\n",
    "  \"kk\": df[\"exercise\"],   # question for observations\n",
    "  \"y\": df[\"outcome\"]      # correctness for observations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = stan_results.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "ASSISTments. (2015). 2015 ASSISTments Skill Builder Data.\n",
    "\n",
    "    Retieved\n",
    "    https://sites.google.com/site/assistmentsdata/home/2015-assistments-skill-builder-data\n",
    "    \n",
    "\n",
    "Stan Development Team. (2019). Stan User’s Guide V.2.2: 1.11 Item-Response Theory Models. \n",
    "\n",
    "\n",
    "    Retrieved\n",
    "    https://mc-stan.org/docs/2_20/stan-users-guide/item-response-models-section.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([\"a\", \"b\", \"c\", \"a\", \"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
